# multi-model-llama-server-TUI
a textual app to run llama.cpp server binaries with a list of your GGUF models
